{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dominique Edwards - Unit 14: Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " #import theano\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#add\n",
    "#import keras\n",
    "N=1000000. #Change this line adjust the number of rows. \n",
    "data=pd.read_csv(\"HIGGS.csv\",nrows=N,header=None)\n",
    "test_data=pd.read_csv(\"HIGGS.csv\",nrows=500000,header=None,skiprows=10500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data.loc[:,0])\n",
    "x = np.array(data.loc[:,1:])\n",
    "x_test = np.array(test_data.loc[:,1:])\n",
    "y_test = np.array(test_data.loc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\tPick 3 or more different architectures (add/subtract layers+neurons) and run the model + score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000000/1000000 [==============================] - 76s 76us/step - loss: 0.6919 - acc: 0.5276\n",
      "Epoch 2/5\n",
      "1000000/1000000 [==============================] - 80s 80us/step - loss: 0.6918 - acc: 0.5287\n",
      "Epoch 3/5\n",
      "1000000/1000000 [==============================] - 88s 88us/step - loss: 0.6918 - acc: 0.5289\n",
      "Epoch 4/5\n",
      "1000000/1000000 [==============================] - 92s 92us/step - loss: 0.6917 - acc: 0.5294 1s - loss: 0.6\n",
      "Epoch 5/5\n",
      "1000000/1000000 [==============================] - 92s 92us/step - loss: 0.6917 - acc: 0.5290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5129048826544258"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Begin \n",
    "\n",
    "##30 - 43 minute marks\n",
    "##50 is the number of neurons, number of neurons dont have the be the same per Layer\n",
    "##Dropout prevent overfitting, prof uses .25 instead of .5 but does not increase speed of the model. \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "## Layer 1\n",
    "model.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "\n",
    "#Other options besides sigmoid (relu, )\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "##Layer 2\n",
    "model.add(Dense(50, kernel_initializer='uniform'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "##Layer 3 added\n",
    "model.add(Dense(50, kernel_initializer='uniform'))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "\n",
    "## 1 put output layer, notice the difference\n",
    "model.add(Dense(1, kernel_initializer='uniform')) \n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "##other optimizers besides sgd\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model.predict(x_test))\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##other optimizers besides sgd\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x, y, epochs=5, batch_size=1000)\n",
    "#roc_auc_score(y_test,model.predict(x_test))\n",
    "#end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\tWith those same 3 architectures, run the SAME architecture but with 2 different (from sigmoid) activation functions.  Google the Keras documentation for a look at different available activations.  [relu, tanh, linear]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\tTake your best model from parts 1&2 and vary the batch size by at least 2 orders of magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\tTake your best model (score) from parts 1&2 and use 3 different kernel initializers. Use a reasonable batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\tTake your best results from #3 and try 3 different optimizers. (LMGTFY) [RMSprop, Adagrad, Adadelta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\tTake all that you’ve learned so far and give your best shot at producing a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: What was the effect of adding more layers/neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert text here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Which parameters gave you the best result and why (in your opinion) did they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert text here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: For #6, how did you decide that your model was ‘done’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
